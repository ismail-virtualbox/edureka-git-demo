{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d90ea143-96bf-43c9-8c10-0e232ffc28f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6817c7f4-ec56-43cc-9fd8-0bb1b2f80346",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0637236d-c6b8-425b-8bf1-ae0271a9f3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as uReq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "167bc62b-f388-483d-b020-4ff73039100a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72ecfdda-9eb7-4099-94c9-d5e2bd7bf27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dividend_return(dividend_check, trading_price):\n",
    "    \n",
    "    if ',' in dividend_check or len(dividend_check.split(' ')) == 3 or len(dividend_check) > 8:\n",
    "        dividends = dividend_check.split(',') if ',' in dividend_check else dividend_check.split(' ', 1)   #stores dividend paid in both cash and bonus shares\n",
    "        \n",
    "        dividend = dividend_in_bonus_cash(dividends, trading_price)\n",
    "    \n",
    "    elif 'B' in dividend_check  and ',' not in dividend_check: \n",
    "        dividend = dividend_in_bonus(dividend_check, trading_price)\n",
    "    \n",
    "    elif '-' in dividend_check:\n",
    "        dividend = dividend_check   #when dividend isn't mentioned on the website\n",
    "    \n",
    "    elif 'B' not in dividend_check and '-' not in dividend_check and ',' not in dividend_check:\n",
    "        dividend = dividend_cash(dividend_check)   #Dividend paid in cash\n",
    "    \n",
    "    return dividend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "502fe003-af19-4a98-88b8-2f3a374bd29e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "('.00 ' in '12.00 16B' or '12' in '11') and ('13' in '12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bd697e5-ff14-46d9-91a8-84839cad0cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dividend_in_bonus_cash(cash_and_bonus_dividends, market_price):\n",
    "    \"\"\"This function calculates total dividend from cash and bonus issues\"\"\"\n",
    "    \n",
    "    for dividend in cash_and_bonus_dividends:\n",
    "        if 'B' not in dividend:\n",
    "            cash_dividend = float(dividend.replace('%', '').strip())\n",
    "            \n",
    "        elif 'B' in dividend:\n",
    "            bonus_dividend = float(dividend.strip().replace('%', '').replace('B',''))\n",
    "    \n",
    "    if '-' not in market_price:\n",
    "        return round(((cash_dividend / 100) * 10) + ((bonus_dividend / 100) * float(market_price)), 2)\n",
    "    \n",
    "    elif '-' in market_price:\n",
    "        return [cash_dividend, bonus_dividend]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "332f0f40-b5b1-411a-b798-0a44ccf2ef39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.5, 2.5]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dividend_in_bonus_cash('2.50, 2.50%B'.split(','), '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c5537a6-03b8-4bc1-9210-e6901eb5dc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dividend_in_bonus(bonus_dividend, market_price):\n",
    "    '''Calculates the amount of last bonus share dividend'''\n",
    "    dividend = float(bonus_dividend.strip().replace('%', '').replace('%','').replace('B',''))\n",
    "    \n",
    "    if '-' not in market_price:\n",
    "        return round(((dividend / 100) * float(market_price)), 2)\n",
    "    \n",
    "    elif '-' in market_price:\n",
    "        return str(dividend) + '%B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef7cd7cd-2a5c-463f-9283-c0e974e89401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dividend_cash(cash_dividend):\n",
    "    return round((float(cash_dividend.replace('%','')) / 100) * 10 , 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce96d389-3c02-4ac7-827a-4eb5b379333b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_eps(pe, market_price):\n",
    "    '''Receives P/E and Trading price as arguments and returns eps'''\n",
    "    if '-' in pe or 'n/a' in pe or '-' in market_price:\n",
    "        eps = pe\n",
    "    else:\n",
    "        eps = round(float(market_price) / float(pe), 2)\n",
    "    \n",
    "    return eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7964f7d4-bcfa-41ff-988b-d8e97a087c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_navps(navps):\n",
    "    if '-' in navps or 'n/a' in navps:\n",
    "        return navps\n",
    "    elif '-' not in navps:\n",
    "        return float(navps.replace(',',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d271ee24-9e9d-4e3d-b24c-0216a3b07ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_eps('2', '12.00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c82e856-21c3-46ea-acd4-6a7176e46303",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_text = uReq.get('https://www.dsebd.org/latest_share_price_scroll_l.php').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9283a19f-0092-428b-85d9-2735d6926f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html_text,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eafd2890-e58e-4e45-bbc9-721fc40d7286",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stocks_tcode_url = soup.find('table', class_ = 'table table-bordered background-white shares-table fixedHeader').find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1283cd82-630c-4fa3-a2df-19277a866b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_temp_data_hold = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2dd83cae-007b-411c-82ab-ce5bd8fca292",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_tcode_url_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83b8fb20-f937-4a99-8fc7-49d71bb1e12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for stock in stocks_tcode_url:\n",
    "    stock_tcode_url_dict[f'{stock.text.strip()}'] = 'https://www.dsebd.org/' + stock['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "671600f3-3e1e-4904-bc03-6e78af2623aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "corporate_disclosures = open('corporate_disclosures.csv', mode = 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34849ab7-9ab4-467e-a6c5-583d9760261f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trading_codes = open('trading_codes.csv', mode = 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66181181-533f-48a9-957e-619a12cf11e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with corporate_disclosures, trading_codes:\n",
    "    \n",
    "    write_disclosures = csv.writer(corporate_disclosures)\n",
    "    write_tcode = csv.writer(trading_codes)\n",
    "    \n",
    "    for stock_tcode, url in sorted(stock_tcode_url_dict.items()):\n",
    "    \n",
    "        try:\n",
    "            #browse and download from the website, store the extracted lxml parsed page on soup_company.\n",
    "            html_text_company = uReq.get(url).text\n",
    "            soup_company = BeautifulSoup(html_text_company,'lxml')\n",
    "        \n",
    "            #group all the table from stock's page and extract disclosures \n",
    "            company_table_data = soup_company.find_all('table', class_ = 'table table-bordered background-white')\n",
    "        \n",
    "            \n",
    "            if '-' not in company_table_data[0].find('tr').find('td').text:\n",
    "                trading_price = company_table_data[0].find('tr').find('td').text.replace(',','') #last trading Price\n",
    "            elif '-' in company_table_data[0].find('tr').find('td').text:\n",
    "                trading_price = company_table_data[0].find('tr').find('td').text\n",
    "        \n",
    "            sector = company_table_data[1].find_all('tr', class_='alt')[1].find_all('td')[1].text #sector\n",
    "        \n",
    "            pe_quarter = company_table_data[4].find('tr', class_ = 'alt').find_all('td')[-1].text #P/E: Quarterly report\n",
    "            eps_quarter = calculate_eps(pe_quarter, trading_price)\n",
    "        \n",
    "            pe_annual = company_table_data[5].find('tr', class_='alt').find_all('td')[-1].text #P/E audited report\n",
    "            eps_annual = calculate_eps(pe_annual, trading_price) \n",
    "        \n",
    "            last_dividend = company_table_data[7].find_all('tr')[-1].find_all('td')[-2].text.strip() #dividend return\n",
    "            dividend_paid = dividend_return(last_dividend, trading_price)\n",
    "    \n",
    "            navps = company_table_data[6].find_all('tr')[-1].find_all('td')[-6].text.strip() #NAVPS\n",
    "            navps_obtained = calculate_navps(navps)\n",
    "\n",
    "            audit_year = company_table_data[7].find_all('tr')[-1].td.text #year of last audited financial report\n",
    "        \n",
    "            market_category = company_table_data[9].find('tr').find_next_sibling('tr').find('td').find_next_sibling('td').text.strip() #category\n",
    "        \n",
    "        \n",
    "            #list_temp_data_hold.append([stock_tcode, trading_price, sector, market_category, recent_dividend, pe_quarter, pe_annual, navps, audit_year])\n",
    "            write_disclosures.writerow([stock_tcode, trading_price, sector, market_category, dividend_paid, eps_quarter, eps_annual, navps_obtained, audit_year])\n",
    "    \n",
    "            write_tcode.writerow([stock_tcode])\n",
    "        \n",
    "        except IndexError:\n",
    "            #browse and download from the website, store the extracted lxml parsed page on soup_company.\n",
    "            html_text_company = uReq.get(url).text\n",
    "            soup_company = BeautifulSoup(html_text_company,'lxml')\n",
    "        \n",
    "            #group all the table from stock's page and extract disclosures \n",
    "            company_table_data = soup_company.find_all('table', class_ = 'table table-bordered background-white')\n",
    "        \n",
    "            \n",
    "            if '-' not in company_table_data[0].find('tr').find('td').text:\n",
    "                trading_price = company_table_data[0].find('tr').find('td').text.replace(',','') #last trading Price\n",
    "            elif '-' in company_table_data[0].find('tr').find('td').text:\n",
    "                trading_price = company_table_data[0].find('tr').find('td').text\n",
    "        \n",
    "            sector = company_table_data[1].find_all('tr', class_='alt')[1].find_all('td')[1].text #sector\n",
    "        \n",
    "            pe_quarter = company_table_data[4].find('tr', class_ = 'alt').find_all('td')[-1].text #P/E: Quarterly report\n",
    "            eps_quarter = calculate_eps(pe_quarter, trading_price)\n",
    "        \n",
    "            pe_annual = company_table_data[5].find('tr', class_='alt').find_all('td')[-1].text #P/E audited report\n",
    "            eps_annual = calculate_eps(pe_annual, trading_price) \n",
    "        \n",
    "            last_dividend = company_table_data[7].find_all('tr')[-1].find_all('td')[-2].text.strip() #dividend return\n",
    "            dividend_paid = dividend_return(last_dividend, trading_price)\n",
    "    \n",
    "            navps = company_table_data[6].find_all('tr')[-1].find_all('td')[-6].text.strip() #NAVPS\n",
    "            navps_obtained = calculate_navps(navps)\n",
    "\n",
    "            audit_year = company_table_data[7].find_all('tr')[-1].td.text #year of last audited financial report\n",
    "        \n",
    "            market_category = company_table_data[9].find('tr').find_next_sibling('tr').find('td').find_next_sibling('td').text.strip() #category\n",
    "        \n",
    "        \n",
    "            #list_temp_data_hold.append([stock_tcode, trading_price, sector, market_category, recent_dividend, pe_quarter, pe_annual, navps, audit_year])\n",
    "            write_disclosures.writerow([stock_tcode, trading_price, sector, market_category, dividend_paid, eps_quarter, eps_annual, navps_obtained, audit_year])\n",
    "    \n",
    "            write_tcode.writerow([stock_tcode])\n",
    "        \n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d20a0cb-96c4-40d4-92d8-b2655abbf578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'502' in soup_company.text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5abf65e8-dd18-41ea-83fd-24b22a9a15e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(company_table_data) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c0b5e8c-581e-4a42-b52f-b1658c4718d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8583f330-3dee-45cc-94dd-b1704be4788c",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3460/4164697690.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "a[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a73edab-ff8e-4718-9115-91dc2a8737b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c7eda9-151d-45c9-a96d-6a9339958864",
   "metadata": {},
   "outputs": [],
   "source": [
    "dividend_return('10.00 B', '27.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecb5ad5-ccf2-43da-a295-479bf0b51909",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall('\\d*\\.?\\d+', '12.22')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e0ba4e44-2971-4eea-a1bf-d421dda2ee8f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "loop_counter = 0\n",
    "for stock_tcode, url in sorted(stock_tcode_url_dict.items()):\n",
    "    \n",
    "    #browse and download from the website, store the extracted lxml parsed page on soup_company.\n",
    "    html_text_company = uReq.get(url).text\n",
    "    soup_company = BeautifulSoup(html_text_company,'lxml')\n",
    "    \n",
    "    #group all the table from stock's page and extract disclosures \n",
    "    company_table_data = soup_company.find_all('table', class_ = 'table table-bordered background-white')\n",
    "    trading_price = company_table_data[0].find('tr').find('td').text #last trading Price\n",
    "    sector = company_table_data[1].find_all('tr', class_='alt')[1].find_all('td')[1].text #sector\n",
    "    pe_quarter = company_table_data[4].find('tr', class_ = 'alt').find_all('td')[-1].text #P/E: Quarterly report\n",
    "    pe_annual = company_table_data[5].find('tr', class_='alt').find_all('td')[-1].text #P/E audited report\n",
    "    \n",
    "    \n",
    "    recent_dividend = company_table_data[7].find_all('tr')[-1].find_all('td')[-2].text.strip() #dividend return\n",
    "    \n",
    "    navps = company_table_data[6].find_all('tr')[-1].find_all('td')[-6].text.strip() #NAVPS\n",
    "    audit_year = company_table_data[7].find_all('tr')[-1].td.text #year of last audited financial report\n",
    "    market_category = company_table_data[9].find('tr').find_next_sibling('tr').find('td').find_next_sibling('td').text.strip() #category\n",
    "    list_temp_data_hold.append([stock_tcode, trading_price, sector, market_category, recent_dividend, pe_quarter, pe_annual, navps, audit_year])\n",
    "    \n",
    "    if loop_counter == 10:\n",
    "        break\n",
    "    loop_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7356cc-7bf5-4142-bead-99d8605cdc7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
